{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "TSRH7vCSnRDb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Project Food recognition\n",
    "A.Y. 2020/2021\n",
    "\n",
    "|  Surname | Name   | Matricola   | Accademic Mail   |\n",
    "|---|---|---|---|\n",
    "|Seroyizhko   | Pavlo     |  982598   | pavlo.seroyizhko@studio.unibo.it |\n",
    "|Wen          | Xiaowei   | 982501  | xiaowei.wen@studio.unibo.it  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5n28JHXH0Ia"
   },
   "source": [
    "# DATA FORMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2630,
     "status": "ok",
     "timestamp": 1619778590927,
     "user": {
      "displayName": "Paul Sero",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRs5JXULevYoKNZaEy4GKfeBmX08-LQpVbH2eELA=s64",
      "userId": "14391136688477581410"
     },
     "user_tz": -120
    },
    "id": "WwxSG3nxOvTv"
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "### For visualizing the outputs ###\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import memory_profiler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1619779053978,
     "user": {
      "displayName": "Paul Sero",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRs5JXULevYoKNZaEy4GKfeBmX08-LQpVbH2eELA=s64",
      "userId": "14391136688477581410"
     },
     "user_tz": -120
    },
    "id": "3PbyMEVAWtny"
   },
   "outputs": [],
   "source": [
    "def getClassName(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return None\n",
    "\n",
    "def getImage(imageObj, img_folder, input_image_size):\n",
    "    # Read and normalize an image\n",
    "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
    "    # Resize\n",
    "    train_img = cv2.resize(train_img, input_image_size)\n",
    "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
    "        return train_img\n",
    "    else: # To handle a black and white image, increase dimensions to 3\n",
    "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
    "        return stacked_img\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "    catAlliasList: list - list of dict of format {categoriId: id_of_class}\n",
    "    key: int - the real category_id\n",
    "    \n",
    "output\n",
    "     int, the associated id to the category_id\n",
    "\n",
    "\"\"\"\n",
    "def getCatAllias(catAlliasList, key):\n",
    "    for al in catAlliasList:\n",
    "        if key in al:\n",
    "              return al[key]\n",
    "\n",
    "    raise NameError('No such key in list')    \n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "input\n",
    "    catIDs: list - list of categories ids\n",
    "output\n",
    "     list of dict of format {categoriId: id_of_class}\n",
    "     \n",
    "     \n",
    "     The function associate the category id, which might be not numerically ordered. \n",
    "     The associated id will be used in forming the output matrix.\n",
    "     \n",
    "     For an output matrix y of shape (batch_size, m, n, n_classes), the only non-0 matrix \n",
    "     for a certein batch will at the position [batch_number(!!),:,:,id_of_class]\n",
    "\"\"\"\n",
    "def createCatAllias(catIDs):\n",
    "    l = []\n",
    "    i=1\n",
    "    for id in catIDs:\n",
    "        l.append({id:i})\n",
    "        i += 1\n",
    "    return l\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input \n",
    "    imageObj: dict - Coco image annotaion\n",
    "    coco: Coco() - Coco object\n",
    "    catIDs: list - list of categories ids\n",
    "    catAllias : list - list of dict of format {categoriId: id_of_class}\n",
    "    input_image_size: tuple - desired image size (width, height)\n",
    "    \n",
    "output\n",
    "    masks: array - (width, height, n_cat) where n_cat is number of cotegories that are on the photo\n",
    "    cats: list - list of id assocciated with categories id taken from catAllias\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def getMasksWithCats(imageObj, coco, catIDs, catAllias, input_image_size):\n",
    "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIDs, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cats = []\n",
    "    masks = np.zeros((input_image_size[0], input_image_size[0], len(anns)))\n",
    "    for a in range(len(anns)):\n",
    "        ann = anns[a]\n",
    "        cat_value = getCatAllias(catAllias, ann['category_id'])\n",
    "        mask = cv2.resize(coco.annToMask(ann), input_image_size)\n",
    "        masks[:,:,a] = mask\n",
    "        cats.append(cat_value)\n",
    "\n",
    "    return masks, cats\n",
    "    \n",
    "def generateData(images, classes, coco, folder, input_image_size, catAllias, mode='train', batch_size=16):\n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    catIds = coco.getCatIds(catNms=classes)\n",
    "    X = []\n",
    "    y = []\n",
    "    for imageObj in images:\n",
    "        X.append(getImage(imageObj, img_folder, input_image_size))\n",
    "        y.append(getNCLassMask(imageObj, coco, catIds, catAllias, input_image_size))\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "\n",
    "    coco: COCO() - A COCO class with annotions of desired dataset\n",
    "    images: lsit - list of images obtained from COCO.loadImgs()\n",
    "    folder: String - root folder with coco images\n",
    "    input_image_size: tuple - desired image size (width, height)\n",
    "    catAllias : list - list of dict of format {categoriId: id_of_class}\n",
    "    mode: String - \"train\" | \"val\" | \"test\"\n",
    "    batch_size: Int - number of augmented images on output after calling next()\n",
    "    \n",
    "output\n",
    "\n",
    "    python generator function\n",
    "    \n",
    "\n",
    "    the function is a python generator function which on calling next() will return\n",
    "    \n",
    "    X: array of augmented images of size (batch_size, n, m, 3), where n is width and m is height\n",
    "    y: array of equally augmented masks of size (batch_size, n, m, n_classes), \n",
    "            array will be 0 for all the 4th dimensions that are not the id number of the category\n",
    "            \n",
    "    every batch is generated by 1 image on which is going to be applied the keras Image Generator\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cocoDataGeneratorWithAug(coco, images, folder, input_image_size, catAllias, mode='train', batch_size=16):\n",
    "    \n",
    "    seed = 32\n",
    "    augGeneratorArgs = dict(featurewise_center = False, \n",
    "                        samplewise_center = False,\n",
    "                        rotation_range = 5, \n",
    "                        width_shift_range = 0.01, \n",
    "                        height_shift_range = 0.01, \n",
    "                        brightness_range = (0.8,1.2),\n",
    "                        shear_range = 0.01,\n",
    "                        zoom_range = [1, 1.25],  \n",
    "                        horizontal_flip = True, \n",
    "                        vertical_flip = False,\n",
    "                        fill_mode = 'reflect',\n",
    "                        data_format = 'channels_last') # the arguments used by keras ImageGenerator for images\n",
    "    \n",
    "    augGeneratorArgs_mask = augGeneratorArgs.copy()\n",
    "    _ = augGeneratorArgs_mask.pop('brightness_range', None) # the arguments used by keras ImageGenerator for mask (same but without brightness)\n",
    "\n",
    "\n",
    "    # Initialize the mask data generator with modified args\n",
    "    image_gen = ImageDataGenerator(**augGeneratorArgs)\n",
    "    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n",
    "    \n",
    "    np.random.seed(seed) # to avoid randomness between image and masks\n",
    "    \n",
    "    # coco parameters\n",
    "    idx = 0 # index of desired image that will generate the batch\n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    #catIds = coco.getCatIds()\n",
    "    n_classes = len(catAllias)+1\n",
    "    # debug\n",
    "    start_time = datetime.now()\n",
    "    start_m = memory_profiler.memory_usage()[0]\n",
    "    \n",
    "    # infinite loop is required by keras model\n",
    "    while(True):       \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"\\n{idx}\")\n",
    "        print(\"passed: {} | memory used: {}\".format(datetime.now()-start_time, memory_profiler.memory_usage()[0]-start_m))\n",
    "        start_time = datetime.now()\n",
    "        start_m = memory_profiler.memory_usage()[0]\n",
    "        \n",
    "        imageObj = images[idx]\n",
    "        img = getImage(imageObj, img_folder, input_image_size) #image_array\n",
    "        \n",
    "        #getMasksWithCats return array of masks for each category on the image and a list of squeezed categories \n",
    "        im_masks, im_cats = getMasksWithCats(imageObj, coco, catIDs, catAllias, input_image_size) \n",
    "        n_masks = im_masks.shape[2]\n",
    "        \n",
    "        #  output\n",
    "        X = np.zeros((batch_size, input_image_size[0], input_image_size[1],3)).astype('float')\n",
    "        y = np.zeros((batch_size, input_image_size[0], input_image_size[1],n_classes)).astype('float')\n",
    "        \n",
    "        \n",
    "        \n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation of the images \n",
    "        # will end up different from the augmentation of the masks\n",
    "        \n",
    "        # image generator\n",
    "        g_x = image_gen.flow(img.reshape((1,)+img.shape), \n",
    "                             batch_size = batch_size, \n",
    "                             seed = seed)\n",
    "        \n",
    "        # masks generators\n",
    "        g_ys = [mask_gen.flow( im_masks[None,:,:,mn,None], \n",
    "                             batch_size = batch_size, \n",
    "                             seed = seed) for mn in range(n_masks)]\n",
    "        \n",
    "        for batch_num in range(batch_size):\n",
    "            X[batch_num] = g_x.next()/255.0\n",
    "            for i in range(n_masks):\n",
    "                y[batch_num,:,:,im_cats[i]] = g_ys[i].next()[:,:,:,0]\n",
    "\n",
    "        yield X, y\n",
    "\n",
    "        if idx >= dataset_size:\n",
    "            idx = 0\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def collectImagesByClasses(coco, filterClasses):\n",
    "    images = []\n",
    "    if filterClasses!=None:\n",
    "        # iterate for each individual class in the list\n",
    "        for className in filterClasses:\n",
    "            # get all images containing given class\n",
    "            catIds = coco.getCatIds(catNms=className)\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "            images += coco.loadImgs(imgIds)\n",
    "    else:\n",
    "        imgIds = coco.getImgIds()\n",
    "        images = coco.loadImgs(imgIds)\n",
    "\n",
    "    # Now, filter out the repeated images    \n",
    "    unique_images = []\n",
    "    for i in range(len(images)):\n",
    "        if images[i] not in unique_images:\n",
    "            unique_images.append(images[i])\n",
    "\n",
    "    dataset_size = len(unique_images)\n",
    "    \n",
    "    print(\"Number of images containing the filter classes:\", dataset_size)\n",
    "    return unique_images\n",
    "\n",
    "def fisrtNMostFreqCat(coco, n):\n",
    "    catsIds = coco.getCatIds()\n",
    "    cats = coco.loadCats(catsIds)\n",
    "    annIds = coco.getAnnIds()\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cat_freq = []\n",
    "    while anns:\n",
    "        cat = anns[0]['category_id']\n",
    "        f = 0\n",
    "        for ann in anns:\n",
    "            if ann['category_id'] == cat:\n",
    "                f += 1\n",
    "        \n",
    "        cat_freq.append({\"cat_id\":cat, \"freq\": f})\n",
    "        \n",
    "        anns = [x for x in anns if x['category_id'] != cat]\n",
    "        \n",
    "    \n",
    "    cat_freq = sorted(cat_freq, key=lambda k: k[\"freq\"], reverse=True)\n",
    "    cat_freq = cat_freq[0:n]\n",
    "    output = []\n",
    "    for c in cat_freq:\n",
    "        output.append(getClassName(c[\"cat_id\"], cats))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1619778595840,
     "user": {
      "displayName": "Paul Sero",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRs5JXULevYoKNZaEy4GKfeBmX08-LQpVbH2eELA=s64",
      "userId": "14391136688477581410"
     },
     "user_tz": -120
    },
    "id": "IC_f8h6UPKQS"
   },
   "outputs": [],
   "source": [
    "img_dir = \"images/\"\n",
    "ann_dir = \"annotations/\"\n",
    "dataType = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1619778613657,
     "user": {
      "displayName": "Paul Sero",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRs5JXULevYoKNZaEy4GKfeBmX08-LQpVbH2eELA=s64",
      "userId": "14391136688477581410"
     },
     "user_tz": -120
    },
    "id": "APbyzQIkHzLg",
    "outputId": "dca89120-2556-4010-fc48-4c363031ef54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.89s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ann_file_train = ann_dir+\"train.json\"\n",
    "ann_file_val = ann_dir+\"val.json\"\n",
    "coco_train=COCO(ann_file_train)\n",
    "coco_val=COCO(ann_file_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1619778617080,
     "user": {
      "displayName": "Paul Sero",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRs5JXULevYoKNZaEy4GKfeBmX08-LQpVbH2eELA=s64",
      "userId": "14391136688477581410"
     },
     "user_tz": -120
    },
    "id": "WVEZxZmFNutu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images containing the filter classes: 10489\n",
      "Number of images containing the filter classes: 541\n"
     ]
    }
   ],
   "source": [
    "filterClasses = fisrtNMostFreqCat(coco_train, 20)\n",
    "catIDs = np.sort(coco_train.getCatIds(catNms=filterClasses))\n",
    "cats = coco_train.loadCats(catIDs)\n",
    "images_train = collectImagesByClasses(coco_train, filterClasses)\n",
    "images_val = collectImagesByClasses(coco_val, filterClasses)\n",
    "img_height = 480\n",
    "img_width = 480\n",
    "imgs_size = (img_width, img_height)\n",
    "cat_allias = createCatAllias(catIDs)\n",
    "\n",
    "n_train_imgs = len(images_train)\n",
    "n_val_imgs = len(images_val)\n",
    "n_classes = len(cats) + 1\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train = cocoDataGeneratorWithAug(coco_train, images_train, os.getcwd(), imgs_size, cat_allias, batch_size=batch_size)\n",
    "dg_val = cocoDataGeneratorWithAug(coco_val, images_val,  os.getcwd(), imgs_size, cat_allias,mode = \"val\", batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvzdAYO8H8bP"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GiwElH9SnRDj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.83s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from TiramisuNet import TiramisuNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(4,), dtype=tf.int32, name=None), inferred_value=[None, 480, 480, 3], name='tf.compat.v1.shape/Shape:0', description=\"created by layer 'tf.compat.v1.shape'\")\n"
     ]
    }
   ],
   "source": [
    "model = TiramisuNet(\n",
    "    input_shape=imgs_size + (3,)\n",
    "    , n_classes=n_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "\n",
      "0\n",
      "passed: 0:00:00.106788 | memory used: 0.0\n",
      "\n",
      "1\n",
      "passed: 0:00:10.925788 | memory used: 452.94921875\n",
      "1/3 [=========>....................] - ETA: 1:12 - loss: 0.8378 - accuracy: 0.0329\n",
      "2\n",
      "passed: 0:00:25.489570 | memory used: 5.796875\n",
      "2/3 [===================>..........] - ETA: 27s - loss: 0.6712 - accuracy: 0.0540 \n",
      "3\n",
      "passed: 0:00:27.159704 | memory used: -56.23046875\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.0542 21\n",
      "\n",
      "0\n",
      "passed: 0:00:00.114669 | memory used: 0.0\n",
      "\n",
      "1\n",
      "passed: 0:00:01.758293 | memory used: 115.8125\n",
      "\n",
      "2\n",
      "passed: 0:00:02.594100 | memory used: -74.1875\n",
      "\n",
      "3\n",
      "passed: 0:00:02.829917 | memory used: -99.0859375\n",
      "3/3 [==============================] - 102s 33s/step - loss: 0.5681 - accuracy: 0.0543 - val_loss: 1.9657 - val_accuracy: 0.0414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = dg_train,\n",
    "                validation_data = dg_val,\n",
    "                steps_per_epoch = 3,\n",
    "                validation_steps = 3,\n",
    "                epochs = 1,\n",
    "                verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
