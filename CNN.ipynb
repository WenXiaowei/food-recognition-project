{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "TSRH7vCSnRDb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Project Food recognition\n",
    "A.Y. 2020/2021\n",
    "\n",
    "|  Surname | Name   | Matricola   | Accademic Mail   |\n",
    "|---|---|---|---|\n",
    "|Seroyizhko   | Pavlo     |  982598   | pavlo.seroyizhko@studio.unibo.it |\n",
    "|Wen          | Xiaowei   | 982501  | xiaowei.wen@studio.unibo.it  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5n28JHXH0Ia"
   },
   "source": [
    "# DATA FORMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwxSG3nxOvTv",
    "outputId": "ac1fdb30-73f3-4a0f-8a03-8a94853a6bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\pavlosero\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.58.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\pavlosero\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from memory_profiler) (5.8.0)\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "### For visualizing the outputs ###\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "!pip install memory_profiler\n",
    "import memory_profiler\n",
    "import threading\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WH31c8rPPVfc"
   },
   "outputs": [],
   "source": [
    "def getClassName(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return None\n",
    "\n",
    "def getImage(imageObj, img_folder, input_image_size):\n",
    "    # Read and normalize an image\n",
    "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
    "    # Resize\n",
    "    train_img = cv2.resize(train_img, input_image_size)\n",
    "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
    "        return train_img\n",
    "    else: # To handle a black and white image, increase dimensions to 3\n",
    "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
    "        return stacked_img\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "    catAlliasList: list - list of dict of format {categoriId: id_of_class}\n",
    "    key: int - the real category_id\n",
    "    \n",
    "output\n",
    "     int, the associated id to the category_id\n",
    "\n",
    "\"\"\"\n",
    "def getCatAllias(catAlliasList, key):\n",
    "    for al in catAlliasList:\n",
    "        if key in al:\n",
    "              return al[key]\n",
    "\n",
    "    return 0 \n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "input\n",
    "    catIDs: list - list of categories ids\n",
    "output\n",
    "     list of dict of format {categoriId: id_of_class}\n",
    "     \n",
    "     \n",
    "     The function associate the category id, which might be not numerically ordered. \n",
    "     The associated id will be used in forming the output matrix.\n",
    "     \n",
    "     For an output matrix y of shape (batch_size, m, n, n_classes), the only non-0 matrix \n",
    "     for a certein batch will at the position [batch_number(!!),:,:,id_of_class]\n",
    "\"\"\"\n",
    "def createCatAllias(catIDs):\n",
    "    l = []\n",
    "    i=1\n",
    "    for id in catIDs:\n",
    "        l.append({id:i})\n",
    "        i += 1\n",
    "    return l\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input \n",
    "    imageObj: dict - Coco image annotaion\n",
    "    coco: Coco() - Coco object\n",
    "    catIDs: list - list of categories ids\n",
    "    catAllias : list - list of dict of format {categoriId: id_of_class}\n",
    "    input_image_size: tuple - desired image size (width, height)\n",
    "    \n",
    "output\n",
    "    masks: array - (width, height, n_cat) where n_cat is number of cotegories that are on the photo\n",
    "    cats: list - list of id assocciated with categories id taken from catAllias\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def getMasksWithCats(imageObj, coco, catIDs, catAllias, input_image_size):\n",
    "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIDs, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cats = []\n",
    "    masks = np.zeros((input_image_size[0], input_image_size[0]))\n",
    "    for a in range(len(anns)):\n",
    "        ann = anns[a]\n",
    "        cat_value = getCatAllias(catAllias, ann['category_id'])\n",
    "        new_mask = cv2.resize(coco.annToMask(ann)*cat_value, input_image_size)\n",
    "        masks = np.maximum(new_mask, masks)\n",
    "        cats.append(cat_value)\n",
    "\n",
    "    return masks.reshape(input_image_size + (1,)), cats\n",
    "    \n",
    "def generateData(images, classes, coco, folder, input_image_size, catAllias, mode='train', batch_size=16):\n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    catIds = coco.getCatIds(catNms=classes)\n",
    "    X = []\n",
    "    y = []\n",
    "    for imageObj in images:\n",
    "        X.append(getImage(imageObj, img_folder, input_image_size))\n",
    "        y.append(getNCLassMask(imageObj, coco, catIds, catAllias, input_image_size))\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "\n",
    "    coco: COCO() - A COCO class with annotions of desired dataset\n",
    "    images: lsit - list of images obtained from COCO.loadImgs()\n",
    "    folder: String - root folder with coco images\n",
    "    input_image_size: tuple - desired image size (width, height)\n",
    "    catAllias : list - list of dict of format {categoriId: id_of_class}\n",
    "    mode: String - \"train\" | \"val\" | \"test\"\n",
    "    batch_size: Int - number of augmented images on output after calling next()\n",
    "    \n",
    "output\n",
    "\n",
    "    python generator function\n",
    "    \n",
    "\n",
    "    the function is a python generator function which on calling next() will return\n",
    "    \n",
    "    X: array of augmented images of size (batch_size, n, m, 3), where n is width and m is height\n",
    "    y: array of equally augmented masks of size (batch_size, n, m, n_classes), \n",
    "            array will be 0 for all the 4th dimensions that are not the id number of the category\n",
    "            \n",
    "    every batch is generated by 1 image on which is going to be applied the keras Image Generator\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cocoDataGenerator(coco, images, folder, input_image_size, catAllias, catIds, mode='train', batch_size=16):\n",
    "    # coco parameters\n",
    "    c = 0 # index of desired image that will generate the batch\n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    #catIds = coco.getCatIds()\n",
    "    n_classes = len(catAllias)+1\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    while(True):\n",
    "        with lock:\n",
    "            img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
    "            mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
    "\n",
    "            for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
    "                imageObj = images[i]\n",
    "\n",
    "                ### Retrieve Image ###\n",
    "                train_img = getImage(imageObj, img_folder, input_image_size)\n",
    "\n",
    "                train_mask, m_cats = getMasksWithCats(imageObj, coco, catIds, catAllias, input_image_size)\n",
    "\n",
    "                # Add to respective batch sized arrays\n",
    "                img[i-c] = train_img\n",
    "                mask[i-c] = train_mask\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                return\n",
    "\n",
    "            c+=batch_size\n",
    "            if(c + batch_size >= dataset_size):\n",
    "                c=0\n",
    "                random.shuffle(images)\n",
    "                \n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "\n",
    "def cocoDataGeneratorWithAug(coco, images, folder, input_image_size, catAllias, catIds, mode='train', batch_size=16):\n",
    "    \n",
    "    seed = 32\n",
    "    augGeneratorArgs = dict(featurewise_center = False, \n",
    "                        samplewise_center = False,\n",
    "                        rotation_range = 5, \n",
    "                        width_shift_range = 0.01, \n",
    "                        height_shift_range = 0.01, \n",
    "                        brightness_range = (0.8,1.2),\n",
    "                        shear_range = 0.01,\n",
    "                        zoom_range = [1, 1.25],  \n",
    "                        horizontal_flip = True, \n",
    "                        vertical_flip = False,\n",
    "                        fill_mode = 'reflect',\n",
    "                        data_format = 'channels_last') # the arguments used by keras ImageGenerator for images\n",
    "    \n",
    "    augGeneratorArgs_mask = augGeneratorArgs.copy()\n",
    "    _ = augGeneratorArgs_mask.pop('brightness_range', None) # the arguments used by keras ImageGenerator for mask (same but without brightness)\n",
    "\n",
    "\n",
    "    # Initialize the mask data generator with modified args\n",
    "    image_gen = ImageDataGenerator(**augGeneratorArgs)\n",
    "    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n",
    "    \n",
    "    np.random.seed(seed) # to avoid randomness between image and masks\n",
    "    \n",
    "    # coco parameters\n",
    "    idx = 0 # index of desired image that will generate the batch\n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    catIds = coco.getCatIds()\n",
    "    n_classes = len(catAllias)+1\n",
    "    # debug\n",
    "    start_time = datetime.now()\n",
    "    start_m = memory_profiler.memory_usage()[0]\n",
    "    \n",
    "    # infinite loop is required by keras model\n",
    "    while(True):       \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(f\"\\n{idx}\")\n",
    "        #print(\"passed: {} | memory used: {}\".format(datetime.now()-start_time, memory_profiler.memory_usage()[0]-start_m))\n",
    "        start_time = datetime.now()\n",
    "        start_m = memory_profiler.memory_usage()[0]\n",
    "        \n",
    "        imageObj = images[idx]\n",
    "        img = getImage(imageObj, img_folder, input_image_size) #image_array\n",
    "        \n",
    "        #getMasksWithCats return array of masks for each category on the image and a list of squeezed categories \n",
    "        im_masks, im_cats = getMasksWithCats(imageObj, coco, catIds, catAllias, input_image_size) \n",
    "        n_masks = im_masks.shape[2]\n",
    "        \n",
    "        #  output\n",
    "        X = np.zeros((batch_size, input_image_size[0], input_image_size[1],3)).astype('float')\n",
    "        y = np.zeros((batch_size, input_image_size[0], input_image_size[1],1)).astype('float')\n",
    "        \n",
    "        \n",
    "        \n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation of the images \n",
    "        # will end up different from the augmentation of the masks\n",
    "        \n",
    "        # image generator\n",
    "        g_x = image_gen.flow(img.reshape((1,)+img.shape), \n",
    "                             batch_size = batch_size, \n",
    "                             seed = seed)\n",
    "        \n",
    "        # masks generators\n",
    "        g_ys = image_gen.flow(im_masks.reshape((1,)+im_masks.shape), \n",
    "                             batch_size = batch_size, \n",
    "                             seed = seed)\n",
    "        for batch_num in range(batch_size):\n",
    "            X[batch_num] = g_x.next()/255.0\n",
    "            y[batch_num] = g_ys.next()/255.0\n",
    "            '''\n",
    "            for i in range(n_masks):\n",
    "                m = g_ys[i].next()\n",
    "                m[m>0.5] = im_cats[i]\n",
    "                 = m#g_ys[i].next()[:, :]\n",
    "\n",
    "            '''\n",
    "            \n",
    "        yield X, y\n",
    "\n",
    "        if idx > dataset_size:\n",
    "            idx = 0\n",
    "            random.shuffle(images)\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def collectImagesByClasses(coco, filterClasses):\n",
    "    images = []\n",
    "    if filterClasses!=None:\n",
    "        # iterate for each individual class in the list\n",
    "        for className in filterClasses:\n",
    "            # get all images containing given class\n",
    "            catIds = coco.getCatIds(catNms=className)\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "            images += coco.loadImgs(imgIds)\n",
    "    else:\n",
    "        imgIds = coco.getImgIds()\n",
    "        images = coco.loadImgs(imgIds)\n",
    "\n",
    "    # Now, filter out the repeated images    \n",
    "    unique_images = []\n",
    "    for i in range(len(images)):\n",
    "        if images[i] not in unique_images:\n",
    "            unique_images.append(images[i])\n",
    "\n",
    "    dataset_size = len(unique_images)\n",
    "    \n",
    "    print(\"Number of images containing the filter classes:\", dataset_size)\n",
    "    return unique_images\n",
    "\n",
    "def fisrtNMostFreqCat(coco, n):\n",
    "    catsIds = coco.getCatIds()\n",
    "    cats = coco.loadCats(catsIds)\n",
    "    annIds = coco.getAnnIds()\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cat_freq = []\n",
    "    while anns:\n",
    "        cat = anns[0]['category_id']\n",
    "        f = 0\n",
    "        for ann in anns:\n",
    "            if ann['category_id'] == cat:\n",
    "                f += 1\n",
    "        \n",
    "        cat_freq.append({\"cat_id\":cat, \"freq\": f})\n",
    "        \n",
    "        anns = [x for x in anns if x['category_id'] != cat]\n",
    "        \n",
    "    \n",
    "    cat_freq = sorted(cat_freq, key=lambda k: k[\"freq\"], reverse=True)\n",
    "    cat_freq = cat_freq[0:n]\n",
    "    output = []\n",
    "    for c in cat_freq:\n",
    "        output.append(getClassName(c[\"cat_id\"], cats))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IC_f8h6UPKQS"
   },
   "outputs": [],
   "source": [
    "img_dir = \"images/\"\n",
    "ann_dir = \"annotations/\"\n",
    "dataType = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APbyzQIkHzLg",
    "outputId": "074dbfec-6707-4ab3-c299-6e0cd8613dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.73s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ann_file_train = ann_dir+\"train.json\"\n",
    "ann_file_val = ann_dir+\"val.json\"\n",
    "coco_train=COCO(ann_file_train)\n",
    "coco_val=COCO(ann_file_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVEZxZmFNutu",
    "outputId": "cae4870f-c012-4eb2-e952-4b499c6abcaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images containing the filter classes: 8906\n",
      "Number of images containing the filter classes: 458\n"
     ]
    }
   ],
   "source": [
    "filterClasses = fisrtNMostFreqCat(coco_train, 18)\n",
    "filterClasses.remove('coffee-with-caffeine')\n",
    "filterClasses.remove('espresso-with-caffeine')\n",
    "catIDs = np.sort(coco_train.getCatIds(catNms=filterClasses))\n",
    "cats = coco_train.loadCats(catIDs)\n",
    "images_train = collectImagesByClasses(coco_train, filterClasses)\n",
    "images_val = collectImagesByClasses(coco_val, filterClasses)\n",
    "img_height = 480\n",
    "img_width = 480\n",
    "imgs_size = (img_width, img_height)\n",
    "cat_allias = createCatAllias(catIDs)\n",
    "\n",
    "n_train_imgs = len(images_train)\n",
    "n_val_imgs = len(images_val)\n",
    "n_classes = len(cats) + 1\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water',\n",
       " 'bread-white',\n",
       " 'salad-leaf-salad-green',\n",
       " 'tomato',\n",
       " 'butter',\n",
       " 'bread-wholemeal',\n",
       " 'carrot',\n",
       " 'coffee-with-caffeine',\n",
       " 'rice',\n",
       " 'egg',\n",
       " 'mixed-vegetables',\n",
       " 'wine-red',\n",
       " 'jam',\n",
       " 'apple',\n",
       " 'potatoes-steamed',\n",
       " 'banana',\n",
       " 'cheese',\n",
       " 'espresso-with-caffeine']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jlp86tQQPVfj"
   },
   "outputs": [],
   "source": [
    "dg_train = cocoDataGenerator(coco_train, images_train, os.getcwd(), imgs_size, cat_allias,catIDs, batch_size=batch_size)\n",
    "dg_val = cocoDataGenerator(coco_val, images_val,  os.getcwd(), imgs_size, cat_allias, catIDs, mode = \"val\", batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzE9UKsuzcCA",
    "outputId": "fea04c90-a753-4103-ffdf-5e698f7009bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample shape [  1 480 480   3]\n",
      "sample_mask shape [  1 480 480   1]\n",
      "sample shape [480 480   3]\n",
      "sample_mask shape[480 480   1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"sample shape {tf.shape(sample_image)}\")\n",
    "print(f\"sample_mask shape {tf.shape(sample_mask)}\")\n",
    "\n",
    "sample_image = tf.reshape(sample_image, [480,480,3])\n",
    "\n",
    "sample_mask = tf.reshape(sample_mask, [480,480,1])\n",
    "\n",
    "print(f\"sample shape {tf.shape(sample_image)}\")\n",
    "print(f\"sample_mask shape{tf.shape(sample_mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvzdAYO8H8bP"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GiwElH9SnRDj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from TiramisuNet import TiramisuNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOdDWIEZPVfk",
    "outputId": "2830c99e-acf2-420f-dc70-9d596df6c3a7"
   },
   "outputs": [],
   "source": [
    "# metteremo questo messaggio per fare piu volte lo stesso training\n",
    "# model = keras.models.load_model('food_recognition')\n",
    "\n",
    "model = None \n",
    "if model is None:\n",
    "  model = TiramisuNet(\n",
    "      input_shape=imgs_size + (3,)\n",
    "      , n_classes=n_classes\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "El-fTloJPVfl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k37pxOALPVfl",
    "outputId": "aa639bdd-5106-4b16-96d1-0cae48002d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 163s 31s/step - loss: 1.1139 - accuracy: 0.3507 - val_loss: 3.2569 - val_accuracy: 0.1614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = dg_train,\n",
    "                validation_data = dg_val,\n",
    "                steps_per_epoch = 5,\n",
    "                validation_steps = 5,\n",
    "                epochs = 1,\n",
    "                verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAgkqQ6zPVfl"
   },
   "outputs": [],
   "source": [
    "# model.save(\"food_recognition\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
